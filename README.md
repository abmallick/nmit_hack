# nmit_hack
# Team: Alpha_Queue
Repository for maintaining code of NMIT hackathon
# clone this repo
# Crawler
1. Environment setup
First of all you will need to download latest executable geckodriver to run latest firefox using selenium: https://github.com/mozilla/geckodriver/releases
The Selenium client bindings tries to locate the geckodriver executable from the system PATH. You will need to add the directory containing the executable to the system path.

2. Running the crawler
Open terminal --> Go to the directoty backend_crawler --> execute python3 crawl.py
This will save all the event (only hackathons for now) into a csv file links.csv

# Finding the word level relationship using a deep learning model:

  # Setup AllenNLP on your local system:


   1. Download and install Conda. link: https://conda.io/docs/download.html

   2. Create a Conda environment with Python 3.6

        conda create -n allennlp python=3.6

   3. Activate the Conda environment. You will need to activate the Conda environment in each terminal in which you want to use AllenNLP.

        source activate allennlp
        
   4. Installing the library and dependencies is simple using pip.

        pip install allennlp
   
 Now open terminal and go to directory "finding_word_tokens_using_deep_learning" --> now execute: python3 trying.py
 You can also edit the 'sentence' inside trying.py (currently "Did Uriah honestly think he could beat the game in under three hours?") to anything you'd like
 
# Website
This will integrate both the files generated by the crawler and the word level embeddings generated by the deep learning model.

# Remaining Part
The task remaining is to merge things together and incorporate into a website, the website part is being developed.
Also, the model needs some more retraining and optimizations to give appropriate tokens.
